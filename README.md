# Reading List of LLM-based Data Science Agents.
### This is the recommended reading list for the paper ”[A Survey on Large Language Model-based Agents for Statistics and Data Science](https://www.arxiv.org/abs/2412.14222)“

![CleanShot 2025-06-16 at 11 53 07@2x](https://github.com/user-attachments/assets/a5c6a516-04a3-4c7d-a069-8317856d1ace)


## **Data Science Agent**
- [AUTOMIND: Adaptive Knowledgeable Agent for Automated Data Science](https://arxiv.org/pdf/2506.10974) ([GitHub](https://github.com/InnovatingAI/AutoMind))
- [ML-Agent: Reinforcing LLM Agents for Autonomous Machine Learning Engineering](https://arxiv.org/pdf/2505.23723) ([Github](https://github.com/MASWorks/ML-Agent))
- [I-MCTS: Enhancing Agentic AutoML via Introspective Monte Carlo Tree Search](https://arxiv.org/pdf/2502.14693)
- [AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML](https://arxiv.org/abs/2410.02958)
- [AutoM3L: An Automated Multimodal Machine Learning Framework with Large Language Models](https://arxiv.org/abs/2408.00665)
- [AutoKaggle: A Multi-Agent Framework for Autonomous Data Science Competitions](https://arxiv.org/abs/2410.20424)
- [ChatGPT as your Personal Data Scientist](https://arxiv.org/abs/2305.13657)
- [Data Interpreter: An LLM Agent For Data Science](https://arxiv.org/abs/2402.18679)
- [Data Formulator 2: Iteratively Creating Rich Visualizations with AI](https://arxiv.org/abs/2408.16119)
- [DS-Agent: Automated Data Science by Empowering Large Language Models with Case-Based Reasoning](https://arxiv.org/abs/2402.17453)
- [Execution-based Evaluation for Data Science Code Generation Models](https://arxiv.org/abs/2211.09374)
- [HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face](https://arxiv.org/abs/2303.17580)
- [InsightPilot: An LLM-Empowered Automated Data Exploration System](https://arxiv.org/abs/2304.00477)
- [Investigating Interaction Modes and User Agency in Human-LLM Collaboration for Domain-Specific Data Analysis](https://arxiv.org/abs/2405.05548)
- [Is GPT-4 a Good Data Analyst?](https://arxiv.org/abs/2305.15038)
- [JarviX: A LLM No-code Platform for Tabular Data Analysis and Optimization](https://arxiv.org/abs/2312.02213)
- [LAMBDA: A Large Model-Based Data Agent](https://arxiv.org/abs/2407.17535) ([Github](https://github.com/AMA-CMFAI/LAMBDA))
- [Large Language Models as Data Preprocessors](https://arxiv.org/abs/2308.16361)
- [Large Language Models for Tabular Data: Progresses and Future Directions](https://dl.acm.org/doi/10.1145/3626772.3661384)
- [Large Language Models for Automated Data Science: Introducing CAAFE for Context-Aware Automated Feature Engineering](https://arxiv.org/abs/2305.03403)
- [LLM-Enhanced Data Management](https://arxiv.org/abs/2402.02643)
- [MatPlotAgent: Method and Evaluation for LLM-Based Agentic Scientific Data Visualization](https://arxiv.org/abs/2402.11453)
- [MLCopilot: Unleashing the Power of Large Language Models in Solving Machine Learning Tasks](https://arxiv.org/abs/2304.14979)
- [OpenAgents: An Open Platform for Language Agents in the Wild](https://arxiv.org/abs/2310.10634)
- [SEED: Domain-Specific Data Curation With Large Language Models](https://arxiv.org/abs/2310.00749)
- [SELA: Tree-Search Enhanced LLM Agents for Automated Machine Learning](https://arxiv.org/abs/2410.17238)
- [Spider2-V: How Far Are Multimodal Agents From Automating Data Science and Engineering Workflows?](https://arxiv.org/abs/2407.10956)
- [TaskWeaver: A Code-First Agent Framework](https://arxiv.org/abs/2311.17541)
- [Text2Analysis: A Benchmark of Table Question Answering with Advanced Data Analysis and Unclear Queries](https://arxiv.org/abs/2312.13671)
- [Training and Evaluating a Jupyter Notebook Data Science Assistant](https://arxiv.org/abs/2201.12901)
- [WaitGPT: Monitoring and Steering Conversational LLM Agent in Data Analysis with On-the-Fly Code Visualization](https://arxiv.org/abs/2408.01703)
- [XInsight: eXplainable Data Analysis Through The Lens of Causality](https://arxiv.org/abs/2207.12718)

## **Evaluation-related Works**

- [Benchmarking Data Science Agents](https://arxiv.org/abs/2402.17168)
- [BLADE: Benchmarking Language Model Agents for Data-Driven Science](https://arxiv.org/abs/2408.09667)
- [DA-Code: Agent Data Science Code Generation Benchmark for Large Language Models](https://arxiv.org/abs/2410.07331)
- [DS-1000: A Natural and Reliable Benchmark for Data Science Code Generation](https://arxiv.org/abs/2211.11501)
- [InfiAgent-DABench: Evaluating Agents on Data Analysis Tasks](https://arxiv.org/abs/2401.05507)
- [Table Meets LLM: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study](https://arxiv.org/abs/2305.13062)

## **Survey**

- [Data Analysis in the Era of Generative AI](https://arxiv.org/abs/2409.18475)
- [Measuring Data Science Automation: A Survey of Evaluation Tools for AI Assistants and Agents](https://arxiv.org/pdf/2506.08800)
- [Large Language Models for Data Science: A Survey](https://www.researchgate.net/profile/Song_Wang84/publication/392594876_Large_Language_Models_for_Data_Science_A_Survey/links/6849ecfdd0be921dfef6ed18/Large-Language-Models-for-Data-Science-A-Survey.pdf)

*Welcome to submit additions*

---

> If you find our work useful in your research, consider citing our paper by:

```bash
@article{sun2024survey,
  title={A Survey on Large Language Model-based Agents for Statistics and Data Science},
  author={Sun, Maojun and Han, Ruijian and Jiang, Binyan and Qi, Houduo and Sun, Defeng and Yuan, Yancheng and Huang, Jian},
  journal={arXiv preprint arXiv:2412.14222},
  year={2024}
}

 @article{sun2024lambda,
  title={LAMBDA: A Large Model Based Data Agent},
  author={Sun, Maojun and Han, Ruijian and Jiang, Binyan and Qi, Houduo and Sun, Defeng and Yuan, Yancheng and Huang, Jian},
  journal={arXiv preprint arXiv:2407.17535},
  year={2024}
}
```
